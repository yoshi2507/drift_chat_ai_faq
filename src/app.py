# src/app.py - Phase 2 AIçµ±åˆå®Œå…¨ç‰ˆ

"""
PIP-Maker ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ Phase 2.0 - AIçµ±åˆå®Œå…¨ç‰ˆ
OpenAIçµ±åˆã€ã‚«ãƒ†ã‚´ãƒªãƒ¼å¯¾å¿œæ¤œç´¢ã€æ„å›³åˆ†é¡æ©Ÿèƒ½æ­è¼‰
"""

import csv
import logging
import uuid
import os
import sys
import aiohttp
import asyncio
import json
from difflib import SequenceMatcher
from typing import Dict, List, Optional, Any
from pathlib import Path
from datetime import datetime

from fastapi import FastAPI, HTTPException, Request
from fastapi.exceptions import RequestValidationError
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from .source_citation_service import SourceCitationService, SourceType, SourceCitation

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
from .error_handling import (
    ChatBotException, 
    DataSourceException, 
    SearchException, 
    ConversationFlowException,
    AIServiceException,
    CategoryException,
    VectorSearchException,
    chatbot_exception_handler,
    general_exception_handler,
)

# è¨­å®šã¨ã‚µãƒ¼ãƒ“ã‚¹
from .config import (
    get_settings, 
    create_complete_ai_system,
    create_data_service,
    create_category_aware_search_service
)

LOGGER = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# ğŸš€ Phase 2: AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
print("ğŸš€ Phase 2: AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
settings = get_settings()

try:
    # å®Œå…¨ãªAIã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆ
    ai_components = create_complete_ai_system()
    
    # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå–å¾—
    data_service = ai_components.get('data_service')
    openai_service = ai_components.get('openai_service')
    intent_classifier = ai_components.get('intent_classifier')
    category_search_engine = ai_components.get('category_search_engine')
    basic_search_service = ai_components.get('basic_search_service')
    
    LOGGER.info("âœ… Phase 2 AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    # åˆ©ç”¨å¯èƒ½æ©Ÿèƒ½ã‚’ãƒ­ã‚°å‡ºåŠ›
    available_features = []
    if data_service:
        available_features.append(f"ãƒ‡ãƒ¼ã‚¿: {type(data_service).__name__}")
    if openai_service:
        available_features.append("OpenAIçµ±åˆ")
    if intent_classifier:
        available_features.append("AIæ„å›³åˆ†é¡")
    if category_search_engine:
        available_features.append("ã‚«ãƒ†ã‚´ãƒªãƒ¼å¯¾å¿œæ¤œç´¢")
    if basic_search_service:
        available_features.append("åŸºæœ¬æ¤œç´¢")
    
    LOGGER.info(f"âœ¨ åˆ©ç”¨å¯èƒ½æ©Ÿèƒ½: {', '.join(available_features)}")
    
except Exception as e:
    LOGGER.error(f"âŒ AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—: {e}")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬ã‚·ã‚¹ãƒ†ãƒ 
    print("ğŸ“„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬ã‚·ã‚¹ãƒ†ãƒ ã§èµ·å‹•")
    try:
        data_service = create_data_service()
        openai_service = None
        intent_classifier = None
        category_search_engine = None
        basic_search_service = None
        
        if data_service:
            # åŸºæœ¬æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½œæˆ
            class BasicSearchService:
                def __init__(self, data_service):
                    self.data_service = data_service
                    self.similarity_threshold = getattr(settings, 'search_similarity_threshold', 0.3)
                
                @staticmethod
                def _similarity(a: str, b: str) -> float:
                    return SequenceMatcher(None, a, b).ratio()
                
                async def search(self, query: str, category: Optional[str] = None, exclude_faqs: bool = False):
                    try:
                        data = await self.data_service.get_qa_data()
                    except Exception as e:
                        raise DataSourceException(f"Q&Aãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ") from e
                    
                    if not data:
                        raise SearchException("è©²å½“ã™ã‚‹å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    
                    query_norm = query.strip().lower()
                    best_match = None
                    best_score = 0.0
                    
                    for row in data:
                        if category and row.get('category', '').lower() != category.lower():
                            continue
                        if exclude_faqs and row.get('notes') == 'ã‚ˆãã‚ã‚‹è³ªå•':
                            continue
                        
                        question = row.get('question', '')
                        if not question:
                            continue
                        
                        score = self._similarity(query_norm, question.lower())
                        if score > best_score:
                            best_match = row
                            best_score = score
                    
                    if not best_match or best_score < self.similarity_threshold:
                        raise SearchException("è©²å½“ã™ã‚‹å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    
                    # SearchResponseã‚¯ãƒ©ã‚¹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
                    class SearchResponse:
                        def __init__(self, answer, confidence, source=None, question=None, response_type="search"):
                            self.answer = answer
                            self.confidence = confidence
                            self.source = source
                            self.question = question
                            self.response_type = response_type
                    
                    return SearchResponse(
                        answer=best_match.get('answer', ''),
                        confidence=round(float(best_score), 2),
                        source=best_match.get('source'),
                        question=best_match.get('question'),
                        response_type="basic_search"
                    )
            
            basic_search_service = BasicSearchService(data_service)
            LOGGER.info("ğŸ“„ åŸºæœ¬æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å®Œäº†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰")
        
    except Exception as fallback_error:
        LOGGER.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆæœŸåŒ–ã‚‚å¤±æ•—: {fallback_error}")
        data_service = None
        basic_search_service = None

# ConversationFlowService ã®åˆæœŸåŒ–
try:
    from .conversation_flow import ConversationFlowService
    
    if data_service:
        conversation_flow_service = ConversationFlowService(data_service)
        LOGGER.info("âœ… å¯¾è©±ãƒ•ãƒ­ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–å®Œäº†")
    else:
        conversation_flow_service = None
        LOGGER.warning("âš ï¸ å¯¾è©±ãƒ•ãƒ­ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹: ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ãªã—ã§ç„¡åŠ¹")
        
except ImportError as e:
    LOGGER.error(f"âŒ ConversationFlowService import error: {e}")
    conversation_flow_service = None

# Phase 3.1: æ ¹æ‹ URLè¡¨ç¤ºã‚µãƒ¼ãƒ“ã‚¹
citation_service = SourceCitationService()
LOGGER.info("âœ… SourceCitationService initialized")

# APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
class CategorySelectionRequest(BaseModel):
    conversation_id: str
    category_id: str

class FAQSelectionRequest(BaseModel):
    conversation_id: str
    faq_id: str

class InquirySubmissionRequest(BaseModel):
    conversation_id: str
    form_data: Dict[str, str]

class SearchQuery(BaseModel):
    question: str = Field(..., title="ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•")
    category: Optional[str] = Field(None, title="è³ªå•ã‚«ãƒ†ã‚´ãƒª")
    conversation_id: Optional[str] = Field(None, title="ä¼šè©±ID")
    use_ai_generation: bool = Field(default=True, title="AIå›ç­”ç”Ÿæˆä½¿ç”¨")
    use_category_optimization: bool = Field(default=True, title="ã‚«ãƒ†ã‚´ãƒªãƒ¼æœ€é©åŒ–ä½¿ç”¨")

class SearchResponse(BaseModel):
    answer: str
    confidence: float
    source: Optional[str] = None
    question: Optional[str] = None
    response_type: str = "search"
    category: Optional[str] = None
    sources_used: List[str] = []
    ai_generated: bool = False
    category_optimized: bool = False
    search_time: Optional[float] = None
    intent_confidence: Optional[float] = None
    method: str = "unknown"
    
    # === Phase 3.1: æ–°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ ===
    citations: Optional[Dict[str, Any]] = None  # å¼•ç”¨æƒ…å ±
    source_count: Optional[int] = None          # ã‚½ãƒ¼ã‚¹æ•°
    verified_sources: Optional[int] = None      # æ¤œè¨¼æ¸ˆã¿ã‚½ãƒ¼ã‚¹æ•°


class FeedbackRequest(BaseModel):
    conversation_id: str = Field(..., description="ä¼šè©±ã®ä¸€æ„è­˜åˆ¥å­")
    rating: str = Field(..., description="positive ã¾ãŸã¯ negative")
    comment: Optional[str] = Field(None, description="è¿½åŠ ã‚³ãƒ¡ãƒ³ãƒˆ")

# Slacké€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹
class SlackNotificationService:
    """Slacké€šçŸ¥é€ä¿¡ç”¨ã®ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆå®Ÿéš›ã®é€ä¿¡æ©Ÿèƒ½ä»˜ãï¼‰"""

    def __init__(self, webhook_url: Optional[str] = None) -> None:
        self.webhook_url = webhook_url
        self.enabled = bool(webhook_url)
        
        # é€šçŸ¥çµ±è¨ˆï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        self.notification_count = 0
        self.successful_notifications = 0
        self.failed_notifications = 0
        self.last_notification_time = None
        
        if self.enabled:
            LOGGER.info(f"âœ… Slacké€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹: æœ‰åŠ¹")
            LOGGER.info(f"   Webhook URL: {webhook_url[:50]}...")
        else:
            LOGGER.info("âš ï¸ Slacké€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹: ç„¡åŠ¹ (Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“)")

    async def _send_to_slack(self, message: dict) -> bool:
        """Slackã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®Ÿéš›ã«é€ä¿¡"""
        if not self.enabled:
            LOGGER.debug("Slacké€šçŸ¥: ç„¡åŠ¹ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            return False
        
        self.notification_count += 1
        
        try:
            LOGGER.info(f"ğŸ“¤ Slacké€šçŸ¥é€ä¿¡é–‹å§‹ (#{self.notification_count})")
            
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(
                    self.webhook_url,
                    json=message,
                    headers={'Content-Type': 'application/json'}
                ) as response:
                    status = response.status
                    response_text = await response.text()
                    
                    if status == 200:
                        self.successful_notifications += 1
                        self.last_notification_time = datetime.now()
                        LOGGER.info(f"âœ… Slacké€šçŸ¥é€ä¿¡æˆåŠŸ (#{self.notification_count})")
                        return True
                    else:
                        self.failed_notifications += 1
                        LOGGER.error(f"âŒ Slacké€šçŸ¥é€ä¿¡å¤±æ•— (#{self.notification_count}) - HTTP {status}: {response_text}")
                        return False
                        
        except asyncio.TimeoutError:
            self.failed_notifications += 1
            LOGGER.error(f"â° Slacké€šçŸ¥ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (#{self.notification_count})")
            return False
        except aiohttp.ClientConnectorError as e:
            self.failed_notifications += 1
            LOGGER.error(f"ğŸ”Œ Slacké€šçŸ¥æ¥ç¶šã‚¨ãƒ©ãƒ¼ (#{self.notification_count}): {e}")
            return False
        except Exception as e:
            self.failed_notifications += 1
            LOGGER.error(f"âŒ Slacké€šçŸ¥äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ (#{self.notification_count}): {e}")
            return False

    async def notify_chat_interaction(
        self,
        question: str,
        answer: str,
        confidence: float,
        user_info: Optional[Dict[str, str]] = None,
        interaction_type: str = "search",
        ai_generated: bool = False,
        category: str = "unknown",
        sources_used: List[str] = []
    ) -> None:
        """ãƒãƒ£ãƒƒãƒˆå¯¾è©±ã®é€šçŸ¥ï¼ˆå®Ÿéš›ã®é€ä¿¡æ©Ÿèƒ½ä»˜ãï¼‰"""
        
        # ãƒ­ã‚°å‡ºåŠ›ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        ai_info = "ğŸ¤– AIç”Ÿæˆ" if ai_generated else "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"
        sources_info = f"({len(sources_used)}ä»¶ã®ã‚½ãƒ¼ã‚¹)" if sources_used else ""
        
        LOGGER.info(
            f"[Slack] {ai_info} {interaction_type}: question={question[:50]}{'...' if len(question) > 50 else ''}, "
            f"answer={answer[:50]}{'...' if len(answer) > 50 else ''}, confidence={confidence:.2f}, "
            f"category={category} {sources_info}"
        )
        
        if not self.enabled:
            return
        
        # å®Ÿéš›ã®Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰ãƒ»é€ä¿¡
        try:
            # ä¿¡é ¼åº¦ã®è‰²åˆ†ã‘
            confidence_color = "#28a745" if confidence >= 0.8 else "#ffc107" if confidence >= 0.6 else "#dc3545"
            
            message = {
                "attachments": [
                    {
                        "color": confidence_color,
                        "blocks": [
                            {
                                "type": "header",
                                "text": {
                                    "type": "plain_text",
                                    "text": f"ğŸ—¨ï¸ æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆå¯¾è©± {ai_info}"
                                }
                            },
                            {
                                "type": "section",
                                "fields": [
                                    {
                                        "type": "mrkdwn",
                                        "text": f"*ğŸ™‹ è³ªå•:*\n{question[:200]}{'...' if len(question) > 200 else ''}"
                                    },
                                    {
                                        "type": "mrkdwn",
                                        "text": f"*ğŸ¤– å›ç­”:*\n{answer[:300]}{'...' if len(answer) > 300 else ''}"
                                    }
                                ]
                            },
                            {
                                "type": "section",
                                "fields": [
                                    {
                                        "type": "mrkdwn",
                                        "text": f"*ğŸ“Š ä¿¡é ¼åº¦:* {confidence:.0%}"
                                    },
                                    {
                                        "type": "mrkdwn",
                                        "text": f"*ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªãƒ¼:* {category}"
                                    },
                                    {
                                        "type": "mrkdwn",
                                        "text": f"*ğŸ” æ¤œç´¢ã‚¿ã‚¤ãƒ—:* {interaction_type}"
                                    },
                                    {
                                        "type": "mrkdwn",
                                        "text": f"*ğŸ“š ã‚½ãƒ¼ã‚¹:* {len(sources_used)}ä»¶"
                                    }
                                ]
                            },
                            {
                                "type": "context",
                                "elements": [
                                    {
                                        "type": "mrkdwn",
                                        "text": f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            }
            
            success = await self._send_to_slack(message)
            
            if success:
                LOGGER.info("âœ… ãƒãƒ£ãƒƒãƒˆå¯¾è©±ã®Slacké€šçŸ¥ãŒæ­£å¸¸ã«é€ä¿¡ã•ã‚Œã¾ã—ãŸ")
            else:
                LOGGER.warning("âš ï¸ ãƒãƒ£ãƒƒãƒˆå¯¾è©±ã®Slacké€šçŸ¥é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")
                
        except Exception as e:
            LOGGER.error(f"âŒ ãƒãƒ£ãƒƒãƒˆå¯¾è©±é€šçŸ¥å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")

    async def notify_inquiry_submission(self, inquiry_data: Dict[str, str]) -> None:
        """ãŠå•ã„åˆã‚ã›é€ä¿¡æ™‚ã®é€šçŸ¥ï¼ˆå®Ÿéš›ã®é€ä¿¡æ©Ÿèƒ½ä»˜ãï¼‰"""
        try:
            company = inquiry_data.get('company', '')
            name = inquiry_data.get('name', '')
            email = inquiry_data.get('email', '')
            inquiry = inquiry_data.get('inquiry', '')
            
            # ãƒ­ã‚°å‡ºåŠ›ï¼ˆå¾“æ¥é€šã‚Šï¼‰
            LOGGER.info(f"[Slack] ğŸ”¥ æ–°ã—ã„ãŠå•ã„åˆã‚ã›: {name} ({company}) - {email}")
            LOGGER.info(f"[Slack] å†…å®¹: {inquiry[:100]}{'...' if len(inquiry) > 100 else ''}")
            
            if not self.enabled:
                return
            
            # é‡è¦åº¦ã®é«˜ã„é€šçŸ¥ãªã®ã§ç›®ç«‹ã¤ãƒ‡ã‚¶ã‚¤ãƒ³
            message = {
                "attachments": [
                    {
                        "color": "#ff6b35",  # ã‚ªãƒ¬ãƒ³ã‚¸è‰²ï¼ˆé‡è¦ï¼‰
                        "blocks": [
                            {
                                "type": "header",
                                "text": {
                                    "type": "plain_text",
                                    "text": "ğŸ”¥ æ–°ã—ã„ãŠå•ã„åˆã‚ã›ãŒå±Šãã¾ã—ãŸï¼"
                                }
                            },
                            {
                                "type": "section",
                                "fields": [
                                    {
                                        "type": "mrkdwn",
                                        "text": f"*ğŸ‘¤ ãŠåå‰:*\n{name}"
                                    },
                                    {
                                        "type": "mrkdwn",
                                        "text": f"*ğŸ¢ ä¼šç¤¾å:*\n{company}"
                                    },
                                    {
                                        "type": "mrkdwn",
                                        "text": f"*ğŸ“§ ãƒ¡ãƒ¼ãƒ«:*\n{email}"
                                    },
                                    {
                                        "type": "mrkdwn",
                                        "text": f"*â° å—ä¿¡æ™‚åˆ»:*\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                                    }
                                ]
                            },
                            {
                                "type": "section",
                                "text": {
                                    "type": "mrkdwn",
                                    "text": f"*ğŸ’¬ ãŠå•ã„åˆã‚ã›å†…å®¹:*\n```{inquiry}```"
                                }
                            },
                            {
                                "type": "actions",
                                "elements": [
                                    {
                                        "type": "button",
                                        "text": {
                                            "type": "plain_text",
                                            "text": "ğŸ“§ ãƒ¡ãƒ¼ãƒ«ã§è¿”ä¿¡"
                                        },
                                        "url": f"mailto:{email}?subject=Re: PIP-Makerã«ã¤ã„ã¦ã®ãŠå•ã„åˆã‚ã›",
                                        "style": "primary"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            }
            
            success = await self._send_to_slack(message)
            
            if success:
                LOGGER.info("âœ… ãŠå•ã„åˆã‚ã›ã®Slacké€šçŸ¥ãŒæ­£å¸¸ã«é€ä¿¡ã•ã‚Œã¾ã—ãŸ")
            else:
                LOGGER.warning("âš ï¸ ãŠå•ã„åˆã‚ã›ã®Slacké€šçŸ¥é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")
                
        except Exception as e:
            LOGGER.error(f"âŒ ãŠå•ã„åˆã‚ã›é€šçŸ¥å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")

    async def notify_faq_selection(
        self, 
        faq_id: str, 
        question: str, 
        category: str,
        user_info: Optional[Dict[str, str]] = None
    ) -> None:
        """FAQé¸æŠã®é€šçŸ¥"""
        LOGGER.info(f"[Slack] FAQé¸æŠ: faq_id={faq_id}, category={category}, question={question}")
        
        if not self.enabled:
            return
        
        try:
            message = {
                "attachments": [
                    {
                        "color": "#36a64f",  # ç·‘è‰²
                        "blocks": [
                            {
                                "type": "section",
                                "text": {
                                    "type": "mrkdwn",
                                    "text": f"ğŸ“‹ *FAQé¸æŠ*\n*ID:* {faq_id}\n*ã‚«ãƒ†ã‚´ãƒªãƒ¼:* {category}\n*è³ªå•:* {question[:100]}{'...' if len(question) > 100 else ''}"
                                }
                            }
                        ]
                    }
                ]
            }
            
            await self._send_to_slack(message)
            
        except Exception as e:
            LOGGER.error(f"âŒ FAQé¸æŠé€šçŸ¥ã§ã‚¨ãƒ©ãƒ¼: {e}")

    async def notify_negative_feedback(self, feedback: Dict[str, str]) -> None:
        """ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®é€šçŸ¥"""
        LOGGER.info(f"[Slack] âš ï¸ ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {feedback}")
        
        if not self.enabled:
            return
        
        try:
            message = {
                "attachments": [
                    {
                        "color": "#dc3545",  # èµ¤è‰²
                        "blocks": [
                            {
                                "type": "section",
                                "text": {
                                    "type": "mrkdwn",
                                    "text": f"âš ï¸ *ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯*\nä¼šè©±ID: {feedback.get('conversation_id', 'N/A')}\nã‚³ãƒ¡ãƒ³ãƒˆ: {feedback.get('comment', 'ãªã—')}"
                                }
                            }
                        ]
                    }
                ]
            }
            
            await self._send_to_slack(message)
            
        except Exception as e:
            LOGGER.error(f"âŒ ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é€šçŸ¥ã§ã‚¨ãƒ©ãƒ¼: {e}")

    async def notify_ai_service_status(self, service_name: str, status: str, details: Dict = None) -> None:
        """AIã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹å¤‰æ›´ã®é€šçŸ¥"""
        LOGGER.info(f"[Slack] ğŸ¤– AIã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹: {service_name} - {status}")
        
        if not self.enabled:
            return
        
        try:
            color = "#28a745" if status == "RELOADED" else "#ffc107"
            
            message = {
                "attachments": [
                    {
                        "color": color,
                        "blocks": [
                            {
                                "type": "section",
                                "text": {
                                    "type": "mrkdwn",
                                    "text": f"ğŸ¤– *AIã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹å¤‰æ›´*\nã‚µãƒ¼ãƒ“ã‚¹: {service_name}\nã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}\nè©³ç´°: {details if details else 'ãªã—'}"
                                }
                            }
                        ]
                    }
                ]
            }
            
            await self._send_to_slack(message)
            
        except Exception as e:
            LOGGER.error(f"âŒ AIã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹é€šçŸ¥ã§ã‚¨ãƒ©ãƒ¼: {e}")

    def get_notification_stats(self) -> Dict[str, any]:
        """é€šçŸ¥çµ±è¨ˆã‚’å–å¾—"""
        return {
            "enabled": self.enabled,
            "webhook_configured": bool(self.webhook_url),
            "total_notifications": self.notification_count,
            "successful_notifications": self.successful_notifications,
            "failed_notifications": self.failed_notifications,
            "success_rate": round(self.successful_notifications / max(self.notification_count, 1) * 100, 1),
            "last_notification_time": self.last_notification_time.isoformat() if self.last_notification_time else None
        }

    async def test_notification(self) -> bool:
        """ãƒ†ã‚¹ãƒˆé€šçŸ¥ã‚’é€ä¿¡"""
        if not self.enabled:
            LOGGER.warning("Slacké€šçŸ¥ãŒç„¡åŠ¹ã®ãŸã‚ã€ãƒ†ã‚¹ãƒˆé€šçŸ¥ã‚’é€ä¿¡ã§ãã¾ã›ã‚“")
            return False
        
        test_message = {
            "attachments": [
                {
                    "color": "#36a64f",
                    "blocks": [
                        {
                            "type": "header",
                            "text": {
                                "type": "plain_text",
                                "text": "ğŸ§ª ãƒ†ã‚¹ãƒˆé€šçŸ¥"
                            }
                        },
                        {
                            "type": "section",
                            "text": {
                                "type": "mrkdwn",
                                "text": f"*PIP-Maker ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ*\nSlacké€šçŸ¥æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚\né€ä¿¡æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                            }
                        }
                    ]
                }
            ]
        }
        
        return await self._send_to_slack(test_message)

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚µãƒ¼ãƒ“ã‚¹
class FeedbackService:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self, slack_service: SlackNotificationService) -> None:
        self.slack_service = slack_service

    async def record_feedback(
        self, 
        conversation_id: str, 
        rating: str, 
        comment: Optional[str],
        context: Optional[Dict] = None
    ) -> None:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²"""
        feedback = {
            "conversation_id": conversation_id,
            "rating": rating,
            "comment": comment,
            "timestamp": datetime.now().isoformat(),
            "context": context
        }
        
        LOGGER.info("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²: %s", feedback)
        
        # ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®å ´åˆã¯Slackã«é€šçŸ¥
        if rating == "negative":
            await self.slack_service.notify_negative_feedback(feedback)

# ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
slack_webhook_url = getattr(settings, 'slack_webhook_url', None)
slack_service = SlackNotificationService(webhook_url=slack_webhook_url)
feedback_service = FeedbackService(slack_service)

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
app_name = getattr(settings, 'app_name', 'PIPâ€‘Maker Chat API')
app_version = getattr(settings, 'app_version', '2.0.0')
app = FastAPI(
    title=f"{app_name} (Phase 2 AIçµ±åˆç‰ˆ)", 
    version=app_version,
    description="OpenAIçµ±åˆã€ã‚«ãƒ†ã‚´ãƒªãƒ¼å¯¾å¿œæ¤œç´¢ã€æ„å›³åˆ†é¡æ©Ÿèƒ½æ­è¼‰"
)

# ä¾‹å¤–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
app.add_exception_handler(ChatBotException, chatbot_exception_handler)
app.add_exception_handler(Exception, general_exception_handler)

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError) -> JSONResponse:
    """pydanticãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã‚’é©åˆ‡ã«å‡¦ç†"""
    return JSONResponse(
        status_code=422,
        content={"error": "å…¥åŠ›å†…å®¹ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚", "details": exc.errors()},
    )

# åŸºæœ¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/", response_class=HTMLResponse)
async def index() -> HTMLResponse:
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰HTMLãƒšãƒ¼ã‚¸ã‚’é…ä¿¡"""
    # HTMLãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
    possible_paths = [
        os.path.join(os.path.dirname(__file__), "..", "index.html"),
        os.path.join(os.getcwd(), "index.html"),
        "index.html"
    ]
    
    html_content = None
    for html_path in possible_paths:
        if os.path.exists(html_path):
            try:
                with open(html_path, encoding="utf-8") as fp:
                    html_content = fp.read()
                LOGGER.info(f"âœ… HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿: {html_path}")
                break
            except Exception as e:
                LOGGER.warning(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {html_path}: {e}")
                continue
    
    if not html_content:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯HTMLï¼ˆPhase 2å¯¾å¿œï¼‰
        html_content = """
        <!DOCTYPE html>
        <html lang="ja">
        <head>
            <meta charset="UTF-8">
            <title>PIP-Maker Chat (Phase 2)</title>
            <style>
                body { font-family: Arial, sans-serif; max-width: 800px; margin: 50px auto; padding: 20px; }
                .success { background: linear-gradient(135deg, #e8f5e8 0%, #d4edda 100%); padding: 20px; border-radius: 12px; border: 1px solid #4caf50; }
                .feature { background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #007bff; }
                .ai-badge { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; }
            </style>
        </head>
        <body>
            <div class="success">
                <h1>ğŸš€ PIP-Maker ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ (Phase 2)</h1>
                <p><span class="ai-badge">ğŸ¤– AIçµ±åˆ</span> ã‚·ã‚¹ãƒ†ãƒ ãŒèµ·å‹•ã—ã¾ã—ãŸï¼</p>
                
                <div class="feature">
                    <h3>âœ¨ æ–°æ©Ÿèƒ½</h3>
                    <ul>
                        <li>ğŸ¤– OpenAIçµ±åˆã«ã‚ˆã‚‹é«˜ç²¾åº¦å›ç­”ç”Ÿæˆ</li>
                        <li>ğŸ¯ AIæ„å›³åˆ†é¡ã«ã‚ˆã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ¼è‡ªå‹•åˆ¤å®š</li>
                        <li>ğŸ” ã‚«ãƒ†ã‚´ãƒªãƒ¼å¯¾å¿œæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³</li>
                        <li>ğŸ“Š ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œå›ç­”æœ€é©åŒ–</li>
                    </ul>
                </div>
                
                <p>ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚</p>
            </div>
        </body>
        </html>"""
        LOGGER.warning("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯HTMLï¼ˆPhase 2å¯¾å¿œï¼‰ã‚’ä½¿ç”¨")
    
    return HTMLResponse(content=html_content)

@app.get("/health")
async def health() -> Dict[str, Any]:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆPhase 2å¯¾å¿œï¼‰"""
    csv_path = getattr(settings, 'csv_file_path', 'unknown')
    
    health_info = {
        "status": "ok", 
        "version": app_version,
        "phase": "2.0-ai-integration",
        "timestamp": datetime.now().isoformat(),
        
        # Phase 2: AIçµ±åˆæ©Ÿèƒ½
        "ai_features": {
            "openai_service": openai_service is not None,
            "intent_classifier": intent_classifier is not None,
            "category_search_engine": category_search_engine is not None,
            "ai_answer_generation": bool(openai_service and settings.ai_answer_generation),
            "ai_intent_classification": bool(intent_classifier and settings.ai_intent_classification)
        },
        
        # åŸºæœ¬ã‚µãƒ¼ãƒ“ã‚¹
        "services": {
            "data_service": type(data_service).__name__ if data_service else "None",
            "basic_search_service": type(basic_search_service).__name__ if basic_search_service else "None",
            "conversation_flow_service": type(conversation_flow_service).__name__ if conversation_flow_service else "None"
        },
        
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±
        "data_sources": {
            "csv_path": csv_path,
            "csv_exists": os.path.exists(csv_path) if csv_path != 'unknown' else False,
            "csv_absolute_path": os.path.abspath(csv_path) if csv_path != 'unknown' else 'unknown',
            "google_sheets_configured": settings.is_google_sheets_configured
        }
    }
    
    # OpenAI ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    if openai_service:
        try:
            openai_health = await openai_service.health_check()
            health_info["ai_services"] = {"openai": openai_health}
        except Exception as e:
            health_info["ai_services"] = {"openai": {"status": "error", "error": str(e)}}
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    if category_search_engine:
        try:
            category_health = await category_search_engine.health_check()
            health_info["ai_services"]["category_search"] = category_health
        except Exception as e:
            health_info["ai_services"]["category_search"] = {"status": "error", "error": str(e)}
    
    # Phase 3.1: å¼•ç”¨ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¿½åŠ 
    health_info["phase3_features"] = {
        "citation_service": citation_service is not None,
        "citation_stats": citation_service.get_citation_stats() if citation_service else None
    }
    
    return health_info

@app.post("/api/search", response_model=SearchResponse)
async def search_endpoint(query: SearchQuery) -> SearchResponse:
    """æ¤œç´¢ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆPhase 3.1: æ ¹æ‹ URLè¡¨ç¤ºæ©Ÿèƒ½çµ±åˆç‰ˆï¼‰"""
    
    # å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if not query.question:
        raise SearchException("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", query="")
    
    question_trimmed = query.question.strip()
    if not question_trimmed:
        raise SearchException("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", query=query.question)
    
    if len(question_trimmed) < 2:
        raise SearchException("ã‚‚ã†å°‘ã—è©³ã—ã„è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", query=question_trimmed)
    
    search_start_time = datetime.now()
    
    # æ¤œç´¢å®Ÿè¡Œï¼ˆæ—¢å­˜ã®æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ã¯ä¿æŒï¼‰
    search_response = None
    qa_results = []  # Q&Aãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    
    # === AIçµ±åˆæ¤œç´¢ ===
    if category_search_engine and query.use_category_optimization:
        try:
            LOGGER.info(f"ğŸ¤– AIçµ±åˆæ¤œç´¢é–‹å§‹: {question_trimmed}")
            
            conversation_context = {
                "conversation_id": query.conversation_id,
                "selected_category": query.category
            } if query.conversation_id else None
            
            result = await category_search_engine.search_with_category_context(
                query=question_trimmed,
                selected_category=query.category,
                conversation_context=conversation_context,
                use_ai_generation=query.use_ai_generation and bool(openai_service)
            )
            
            # Q&Aãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå¼•ç”¨ç”¨ï¼‰
            if hasattr(category_search_engine, 'get_source_qa_data'):
                qa_results = await category_search_engine.get_source_qa_data(question_trimmed, query.category)
            elif data_service:
                try:
                    all_qa_data = await data_service.get_qa_data()
                    # ç°¡å˜ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    qa_results = [
                        item for item in all_qa_data 
                        if query.category is None or item.get('category', '').lower() == query.category.lower()
                    ][:5]  # æœ€å¤§5ä»¶
                except Exception as e:
                    LOGGER.warning(f"Q&Aãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
                    qa_results = []
            
            search_response = SearchResponse(
                answer=result['answer'],
                confidence=result['confidence'],
                source=result.get('sources_used', [None])[0],
                question=question_trimmed,
                response_type="ai_integrated",
                category=result.get('category'),
                sources_used=result.get('sources_used', []),
                ai_generated=result.get('ai_generated', False),
                category_optimized=result.get('category_optimized', True),
                search_time=result.get('search_time'),
                intent_confidence=result.get('intent_confidence'),
                method=result.get('method', 'ai_integrated')
            )
            
            LOGGER.info(f"âœ… AIçµ±åˆæ¤œç´¢æˆåŠŸ: ä¿¡é ¼åº¦={result['confidence']:.2f}")
            
        except Exception as ai_error:
            LOGGER.warning(f"âš ï¸ AIçµ±åˆæ¤œç´¢å¤±æ•—: {ai_error}")
            search_response = None
    
    # === åŸºæœ¬æ¤œç´¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ ===
    if not search_response and basic_search_service:
        try:
            LOGGER.info(f"ğŸ“„ åŸºæœ¬æ¤œç´¢é–‹å§‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰: {question_trimmed}")
            
            result = await basic_search_service.search(
                question_trimmed,
                query.category,
                exclude_faqs=False
            )
            
            # Q&Aãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå¼•ç”¨ç”¨ï¼‰
            if data_service:
                try:
                    all_qa_data = await data_service.get_qa_data()
                    qa_results = [
                        item for item in all_qa_data 
                        if question_trimmed.lower() in item.get('question', '').lower() or
                        question_trimmed.lower() in item.get('answer', '').lower()
                    ][:3]  # æœ€å¤§3ä»¶
                except Exception as e:
                    LOGGER.warning(f"Q&Aãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")
                    qa_results = []
            
            search_time = (datetime.now() - search_start_time).total_seconds()
            
            search_response = SearchResponse(
                answer=result.answer,
                confidence=result.confidence,
                source=result.source,
                question=result.question,
                response_type="basic_search",
                category=query.category,
                sources_used=[result.source] if result.source else [],
                ai_generated=False,
                category_optimized=False,
                search_time=search_time,
                method="basic_fallback"
            )
            
            LOGGER.info(f"âœ… åŸºæœ¬æ¤œç´¢æˆåŠŸï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰: ä¿¡é ¼åº¦={result.confidence:.2f}")
            
        except Exception as exc:
            LOGGER.error(f"âŒ åŸºæœ¬æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {exc}")
            raise SearchException("æ¤œç´¢å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚") from exc
    
    if not search_response:
        raise SearchException("æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")
    
    # === Phase 3.1: æ ¹æ‹ URLè¡¨ç¤ºæ©Ÿèƒ½ã®çµ±åˆ ===
    try:
        LOGGER.info(f"ğŸ“š å¼•ç”¨æƒ…å ±ç”Ÿæˆé–‹å§‹: {len(qa_results)}ä»¶ã®Q&Aãƒ‡ãƒ¼ã‚¿")
        
        # åŒ…æ‹¬çš„ãªå¼•ç”¨æƒ…å ±ã‚’å–å¾—
        citations = await citation_service.get_comprehensive_citations(
            query=question_trimmed,
            category=query.category or "unknown",
            qa_results=qa_results
        )
        
        # æ¤œç´¢çµæœã«å¼•ç”¨æƒ…å ±ã‚’è¿½åŠ 
        search_response.citations = citations
        search_response.source_count = citations.get('total_sources', 0)
        
        # æ¤œè¨¼æ¸ˆã¿ã‚½ãƒ¼ã‚¹æ•°ã‚’è¨ˆç®—
        verified_count = 0
        for citation in citations.get('citations', []):
            if citation.get('verified'):
                verified_count += 1
        search_response.verified_sources = verified_count
        
        LOGGER.info(f"âœ… å¼•ç”¨æƒ…å ±ç”Ÿæˆå®Œäº†: {citations['total_sources']}ä»¶ã®ã‚½ãƒ¼ã‚¹ã€{verified_count}ä»¶æ¤œè¨¼æ¸ˆã¿")
        
    except Exception as citation_error:
        LOGGER.warning(f"âš ï¸ å¼•ç”¨æƒ…å ±ç”Ÿæˆå¤±æ•—: {citation_error}")
        # å¼•ç”¨æƒ…å ±ã®ç”Ÿæˆã«å¤±æ•—ã—ã¦ã‚‚æ¤œç´¢çµæœã¯è¿”ã™
        search_response.citations = {
            "citations": [],
            "total_sources": 0,
            "showing": 0,
            "has_more": False
        }
        search_response.source_count = 0
        search_response.verified_sources = 0
    
    # Slacké€šçŸ¥ï¼ˆå¼•ç”¨æƒ…å ±ä»˜ãï¼‰
    try:
        citation_summary = f"å¼•ç”¨: {search_response.source_count}ä»¶" if search_response.source_count else "å¼•ç”¨ãªã—"
        
        await slack_service.notify_chat_interaction(
            question=question_trimmed,
            answer=search_response.answer,
            confidence=search_response.confidence,
            interaction_type=search_response.method,
            ai_generated=search_response.ai_generated,
            category=search_response.category or "unknown",
            sources_used=search_response.sources_used + [citation_summary]
        )
    except Exception as slack_error:
        LOGGER.warning(f"Slacké€šçŸ¥å¤±æ•—: {slack_error}")
    
    return search_response

@app.post("/api/feedback")
async def feedback_endpoint(feedback: FeedbackRequest) -> Dict[str, str]:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    if feedback.rating not in ["positive", "negative"]:
        raise HTTPException(
            status_code=422, 
            detail="ratingã¯ 'positive' ã¾ãŸã¯ 'negative' ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        )
    
    context = None
    if conversation_flow_service:
        context_obj = conversation_flow_service.get_conversation_context(feedback.conversation_id)
        if context_obj:
            context = {
                "state": getattr(context_obj, 'state', 'unknown'),
                "category": getattr(context_obj, 'selected_category', None),
                "interaction_count": getattr(context_obj, 'interaction_count', 0)
            }
    
    await feedback_service.record_feedback(
        conversation_id=feedback.conversation_id,
        rating=feedback.rating,
        comment=feedback.comment,
        context=context
    )
    
    return {"status": "received"}

# === å¯¾è©±ãƒ•ãƒ­ãƒ¼ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ===

@app.get("/api/conversation/welcome")
async def get_welcome_message() -> Dict[str, Any]:
    """åˆæœŸã®æ­“è¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠè‚¢ã‚’è¿”ã™"""
    if not conversation_flow_service:
        return {
            "message": "ã“ã‚“ã«ã¡ã¯ï¼PIP-Makerã«ã¤ã„ã¦ã®ã”è³ªå•ã‚’ãŠæ°—è»½ã«ã©ã†ãã€‚",
            "type": "welcome"
        }
    
    try:
        return await conversation_flow_service.get_welcome_message()
    except Exception as e:
        LOGGER.error(f"Welcome message error: {e}")
        return {
            "message": "ã“ã‚“ã«ã¡ã¯ï¼PIP-Makerã«ã¤ã„ã¦ã®ã”è³ªå•ã‚’ãŠæ°—è»½ã«ã©ã†ãã€‚",
            "type": "welcome_fallback"
        }

@app.post("/api/conversation/category")
async def select_category_endpoint(request: CategorySelectionRequest) -> Dict[str, Any]:
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠå‡¦ç†"""
    if not conversation_flow_service:
        raise ConversationFlowException(
            "å¯¾è©±ãƒ•ãƒ­ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“",
            conversation_id=request.conversation_id,
            state="service_unavailable"
        )
    
    try:
        LOGGER.info(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠ: {request.category_id} (ä¼šè©±ID: {request.conversation_id})")
        
        result = await conversation_flow_service.select_category(
            request.conversation_id, 
            request.category_id
        )
        
        LOGGER.info(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠå‡¦ç†å®Œäº†: {request.category_id}")
        return result
        
    except ValueError as exc:
        raise ConversationFlowException(
            f"ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(exc)}",
            conversation_id=request.conversation_id,
            state="category_selection"
        ) from exc
    except Exception as exc:
        LOGGER.error(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠå‡¦ç†ã‚¨ãƒ©ãƒ¼: {exc}")
        raise ConversationFlowException(
            "ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
            conversation_id=request.conversation_id,
            state="category_selection"
        ) from exc

@app.post("/api/conversation/faq")
async def select_faq_endpoint(request: FAQSelectionRequest) -> Dict[str, Any]:
    """FAQé¸æŠå‡¦ç†"""
    if not conversation_flow_service:
        raise ConversationFlowException(
            "å¯¾è©±ãƒ•ãƒ­ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“",
            conversation_id=request.conversation_id,
            state="service_unavailable"
        )
    
    try:
        LOGGER.info(f"FAQé¸æŠ: {request.faq_id} (ä¼šè©±ID: {request.conversation_id})")
        
        result = await conversation_flow_service.select_faq(
            request.conversation_id,
            request.faq_id
        )
        
        # Slacké€šçŸ¥
        await slack_service.notify_faq_selection(
            faq_id=request.faq_id,
            question=result.get("message", "")[:100],
            category="unknown"
        )
        
        return result
        
    except ValueError as exc:
        raise ConversationFlowException(
            f"FAQé¸æŠã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(exc)}",
            conversation_id=request.conversation_id,
            state="faq_selection"
        ) from exc
    except Exception as exc:
        LOGGER.error(f"FAQé¸æŠå‡¦ç†ã‚¨ãƒ©ãƒ¼: {exc}")
        raise ConversationFlowException(
            "FAQé¸æŠã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
            conversation_id=request.conversation_id,
            state="faq_selection"
        ) from exc

@app.post("/api/conversation/inquiry")
async def submit_inquiry_endpoint(request: InquirySubmissionRequest) -> Dict[str, Any]:
    """ãŠå•ã„åˆã‚ã›é€ä¿¡å‡¦ç†"""
    if not conversation_flow_service:
        raise HTTPException(status_code=500, detail="å¯¾è©±ãƒ•ãƒ­ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    try:
        LOGGER.info(f"ãŠå•ã„åˆã‚ã›é€ä¿¡: (ä¼šè©±ID: {request.conversation_id})")
        
        result = await conversation_flow_service.submit_inquiry(
            request.conversation_id,
            request.form_data
        )
        
        # Slacké€šçŸ¥
        await slack_service.notify_inquiry_submission(request.form_data)
        
        return result
        
    except ValueError as exc:
        LOGGER.error(f"ãŠå•ã„åˆã‚ã›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {exc}")
        raise HTTPException(status_code=400, detail=str(exc))
    except Exception as exc:
        LOGGER.error(f"ãŠå•ã„åˆã‚ã›é€ä¿¡å‡¦ç†ã‚¨ãƒ©ãƒ¼: {exc}")
        raise HTTPException(status_code=500, detail="ãŠå•ã„åˆã‚ã›é€ä¿¡ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")

# === Phase 2: AIçµ±åˆãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ===

@app.get("/debug/ai-status")
async def debug_ai_status() -> Dict[str, Any]:
    """AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª"""
    ai_status = {
        "timestamp": datetime.now().isoformat(),
        "phase": "2.0-ai-integration",
        "components": {},
        "configuration": {},
        "health_checks": {}
    }
    
    # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçŠ¶æ…‹
    ai_status["components"] = {
        "data_service": {
            "available": data_service is not None,
            "type": type(data_service).__name__ if data_service else None
        },
        "openai_service": {
            "available": openai_service is not None,
            "configured": bool(settings.openai_api_key)
        },
        "intent_classifier": {
            "available": intent_classifier is not None,
            "ai_enabled": bool(intent_classifier and openai_service)
        },
        "category_search_engine": {
            "available": category_search_engine is not None,
            "ai_enhanced": bool(category_search_engine and openai_service)
        },
        "basic_search_service": {
            "available": basic_search_service is not None,
            "fallback_ready": bool(basic_search_service)
        }
    }
    
    # è¨­å®šæƒ…å ±
    ai_status["configuration"] = {
        "ai_answer_generation": settings.ai_answer_generation,
        "ai_intent_classification": settings.ai_intent_classification,
        "category_search_enabled": settings.category_search_enabled,
        "openai_model": settings.openai_model,
        "openai_requests_per_minute": settings.openai_requests_per_minute,
        "openai_daily_budget": settings.openai_daily_budget
    }
    
    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    if openai_service:
        try:
            openai_health = await openai_service.health_check()
            ai_status["health_checks"]["openai"] = openai_health
        except Exception as e:
            ai_status["health_checks"]["openai"] = {"status": "error", "error": str(e)}
    
    if category_search_engine:
        try:
            category_health = await category_search_engine.health_check()
            ai_status["health_checks"]["category_search"] = category_health
        except Exception as e:
            ai_status["health_checks"]["category_search"] = {"status": "error", "error": str(e)}
    
    return ai_status

@app.get("/debug/status")
async def debug_status() -> Dict[str, Any]:
    """ç·åˆãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆPhase 2å¯¾å¿œï¼‰"""
    csv_path = getattr(settings, 'csv_file_path', 'unknown')
    
    debug_info = {
        "system": {
            "working_directory": os.getcwd(),
            "phase": "2.0-ai-integration",
            "timestamp": datetime.now().isoformat()
        },
        "data_sources": {
            "csv_path": csv_path,
            "csv_absolute_path": os.path.abspath(csv_path) if csv_path != 'unknown' else 'unknown',
            "csv_exists": os.path.exists(csv_path) if csv_path != 'unknown' else False,
            "google_sheets_configured": settings.is_google_sheets_configured
        },
        "services": {
            "data_service": type(data_service).__name__ if data_service else "None",
            "conversation_flow_service": type(conversation_flow_service).__name__ if conversation_flow_service else "None",
            "basic_search_service": type(basic_search_service).__name__ if basic_search_service else "None"
        },
        "ai_services": {
            "openai_service": type(openai_service).__name__ if openai_service else "None",
            "intent_classifier": type(intent_classifier).__name__ if intent_classifier else "None",
            "category_search_engine": type(category_search_engine).__name__ if category_search_engine else "None"
        },
        "environment": {
            "directory_contents": list(os.listdir(os.getcwd())),
            "src_directory_contents": list(os.listdir('./src')) if os.path.exists('./src') else "src directory not found"
        }
    }

# === Phase 3.1: å¼•ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ===

@app.get("/debug/citations")
async def debug_citations() -> Dict[str, Any]:
    """å¼•ç”¨ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±"""
    try:
        stats = citation_service.get_citation_stats()
        
        # ã‚µãƒ³ãƒ—ãƒ«å¼•ç”¨æƒ…å ±ã‚’ç”Ÿæˆ
        sample_qa = {
            'question': 'PIP-Makerã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ',
            'answer': 'PIP-Makerã¯åŠ¹ç‡çš„ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã‚’æ”¯æ´ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚',
            'source': 'https://www.pip-maker.com/product è£½å“æ¦‚è¦ãƒšãƒ¼ã‚¸',
            'category': 'about'
        }
        
        sample_citations = citation_service.extract_citations_from_qa_data(sample_qa)
        sample_display = citation_service.format_citations_for_display(sample_citations)
        
        return {
            "citation_service_stats": stats,
            "sample_citation_extraction": {
                "input": sample_qa,
                "extracted_citations": [c.to_dict() for c in sample_citations],
                "formatted_display": sample_display
            },
            "pip_maker_url_suggestions": [
                c.to_dict() for c in citation_service.generate_pip_maker_related_urls(
                    "PIP-Makerã®æ©Ÿèƒ½ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„", "features"
                )
            ],
            "system_info": {
                "cache_enabled": True,
                "cache_duration_hours": citation_service.cache_duration.total_seconds() / 3600,
                "pip_maker_patterns": citation_service.pip_maker_patterns
            }
        }
    except Exception as e:
        return {
            "error": str(e),
            "citation_service_available": citation_service is not None
        }

@app.post("/admin/citations/verify-urls")
async def verify_citations_urls() -> Dict[str, Any]:
    """ç®¡ç†è€…ç”¨ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿URLã®ä¸€æ‹¬æ¤œè¨¼"""
    try:
        verified_results = []
        
        for url in list(citation_service.url_cache.keys())[:10]:  # æœ€å¤§10ä»¶
            is_accessible, status = await citation_service.verify_url_accessibility(url)
            verified_results.append({
                "url": url,
                "accessible": is_accessible,
                "status": status
            })
        
        stats = citation_service.get_citation_stats()
        
        return {
            "verification_results": verified_results,
            "cache_stats": stats,
            "message": f"{len(verified_results)}ä»¶ã®URLã‚’æ¤œè¨¼ã—ã¾ã—ãŸ"
        }
        
    except Exception as e:
        return {
            "error": str(e),
            "message": "URLæ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
        }

@app.get("/debug/citations/url-patterns")
async def debug_citation_url_patterns() -> Dict[str, Any]:
    """å¼•ç”¨URLãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
    test_urls = [
        "https://www.pip-maker.com/product",
        "https://info.pip-maker.com/manual/pdf/PIP-Maker_creator.pdf",
        "https://support.pip-maker.com/faq",
        "https://blog.pip-maker.com/news/update",
        "https://example.com/unknown"
    ]
    
    pattern_results = []
    for url in test_urls:
        source_type = citation_service.classify_source_type(url)
        pattern_results.append({
            "url": url,
            "classified_type": source_type.value,
            "type_label": citation_service._get_source_type_label(source_type),
            "icon": citation_service._get_source_icon(source_type)
        })
    
    return {
        "pip_maker_patterns": citation_service.pip_maker_patterns,
        "pattern_test_results": pattern_results,
        "source_type_mapping": {
            "INTERNAL_DATA": "å†…éƒ¨ãƒ‡ãƒ¼ã‚¿",
            "OFFICIAL_WEBSITE": "å…¬å¼ã‚µã‚¤ãƒˆ", 
            "PDF_MANUAL": "PDFãƒãƒ‹ãƒ¥ã‚¢ãƒ«",
            "FAQ": "ã‚ˆãã‚ã‚‹è³ªå•",
            "DOCUMENTATION": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
            "BLOG_POST": "ãƒ–ãƒ­ã‚°è¨˜äº‹",
            "UNKNOWN": "å‚è€ƒè³‡æ–™"
        }
    }

@app.post("/admin/citations/test-extraction")
async def test_citation_extraction(qa_item: Dict[str, str]) -> Dict[str, Any]:
    """ç®¡ç†è€…ç”¨ï¼šå¼•ç”¨æŠ½å‡ºãƒ†ã‚¹ãƒˆ"""
    try:
        # å¼•ç”¨æƒ…å ±ã‚’æŠ½å‡º
        citations = citation_service.extract_citations_from_qa_data(qa_item)
        
        # è¡¨ç¤ºç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted_display = citation_service.format_citations_for_display(citations)
        
        # URLæ¤œè¨¼ï¼ˆéåŒæœŸï¼‰
        enhanced_citations = await citation_service.enhance_citations_with_verification(citations)
        
        return {
            "input_qa": qa_item,
            "extracted_citations": [c.to_dict() for c in citations],
            "enhanced_citations": [c.to_dict() for c in enhanced_citations],
            "formatted_display": formatted_display,
            "extraction_success": len(citations) > 0
        }
        
    except Exception as e:
        return {
            "error": str(e),
            "input_qa": qa_item
        }

@app.get("/debug/citations/cache-status")
async def debug_citation_cache_status() -> Dict[str, Any]:
    """å¼•ç”¨ã‚·ã‚¹ãƒ†ãƒ ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹ç¢ºèª"""
    cache_details = []
    
    for url, (accessible, timestamp) in citation_service.url_cache.items():
        age_seconds = (datetime.now() - timestamp).total_seconds()
        is_expired = age_seconds > citation_service.cache_duration.total_seconds()
        
        cache_details.append({
            "url": url,
            "accessible": accessible,
            "cached_at": timestamp.isoformat(),
            "age_seconds": age_seconds,
            "age_hours": round(age_seconds / 3600, 2),
            "is_expired": is_expired
        })
    
    # æœ€æ–°10ä»¶ã®ã¿è¡¨ç¤º
    cache_details.sort(key=lambda x: x["cached_at"], reverse=True)
    
    stats = citation_service.get_citation_stats()
    
    return {
        "cache_overview": stats,
        "cache_duration_hours": citation_service.cache_duration.total_seconds() / 3600,
        "recent_cached_urls": cache_details[:10],
        "total_cached_urls": len(cache_details),
        "expired_urls_count": len([c for c in cache_details if c["is_expired"]])
    }

@app.delete("/admin/citations/clear-cache")
async def clear_citation_cache() -> Dict[str, Any]:
    """ç®¡ç†è€…ç”¨ï¼šå¼•ç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªã‚¢"""
    try:
        original_cache_size = len(citation_service.url_cache)
        citation_service.url_cache.clear()
        
        LOGGER.info(f"å¼•ç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢: {original_cache_size}ä»¶ã®URLã‚’å‰Šé™¤")
        
        return {
            "status": "success",
            "message": f"{original_cache_size}ä»¶ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ",
            "cleared_count": original_cache_size,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        LOGGER.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "status": "error",
            "message": f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã«å¤±æ•—: {str(e)}"
        }

@app.post("/admin/citations/bulk-verify")
async def bulk_verify_pip_maker_urls() -> Dict[str, Any]:
    """ç®¡ç†è€…ç”¨ï¼šPIP-Makeré–¢é€£URLã®ä¸€æ‹¬æ¤œè¨¼"""
    pip_maker_urls = [
        "https://www.pip-maker.com/",
        "https://www.pip-maker.com/product",
        "https://www.pip-maker.com/features", 
        "https://www.pip-maker.com/pricing",
        "https://www.pip-maker.com/case-studies",
        "https://info.pip-maker.com/manual/pdf/PIP-Maker_creator.pdf",
        "https://support.pip-maker.com/",
        "https://blog.pip-maker.com/"
    ]
    
    verification_results = []
    successful_verifications = 0
    
    for url in pip_maker_urls:
        try:
            is_accessible, status = await citation_service.verify_url_accessibility(url)
            
            if is_accessible:
                successful_verifications += 1
            
            verification_results.append({
                "url": url,
                "accessible": is_accessible,
                "status": status,
                "source_type": citation_service.classify_source_type(url).value
            })
            
        except Exception as e:
            verification_results.append({
                "url": url,
                "accessible": False,
                "status": f"ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "source_type": "unknown"
            })
    
    return {
        "verification_summary": {
            "total_urls": len(pip_maker_urls),
            "successful_verifications": successful_verifications,
            "success_rate": round(successful_verifications / len(pip_maker_urls) * 100, 1)
        },
        "verification_results": verification_results,
        "timestamp": datetime.now().isoformat()
    }


@app.post("/admin/citations/verify-urls")
async def verify_citations_urls() -> Dict[str, Any]:
    """ç®¡ç†è€…ç”¨ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿URLã®ä¸€æ‹¬æ¤œè¨¼"""
    try:
        verified_results = []
        
        for url in list(citation_service.url_cache.keys())[:10]:  # æœ€å¤§10ä»¶
            is_accessible, status = await citation_service.verify_url_accessibility(url)
            verified_results.append({
                "url": url,
                "accessible": is_accessible,
                "status": status
            })
        
        stats = citation_service.get_citation_stats()
        
        return {
            "verification_results": verified_results,
            "cache_stats": stats,
            "message": f"{len(verified_results)}ä»¶ã®URLã‚’æ¤œè¨¼ã—ã¾ã—ãŸ"
        }
        
    except Exception as e:
        return {
            "error": str(e),
            "message": "URLæ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
        }
    
    # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã®è©³ç´°æƒ…å ±
    if data_service and hasattr(data_service, 'get_cache_info'):
        debug_info['data_service_cache'] = data_service.get_cache_info()
    
    # OpenAIä½¿ç”¨çµ±è¨ˆ
    if openai_service and hasattr(openai_service, 'get_usage_stats'):
        debug_info['openai_usage_stats'] = openai_service.get_usage_stats()
    
    return debug_info

# === Phase 2: AIç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ===

@app.post("/admin/ai/reload")
async def reload_ai_services() -> Dict[str, Any]:
    """AIã‚µãƒ¼ãƒ“ã‚¹ã®å†èª­ã¿è¾¼ã¿ï¼ˆç®¡ç†è€…ç”¨ï¼‰"""
    global openai_service, intent_classifier, category_search_engine
    
    try:
        LOGGER.info("ğŸ”„ AIã‚µãƒ¼ãƒ“ã‚¹å†èª­ã¿è¾¼ã¿é–‹å§‹...")
        
        # AIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å†ä½œæˆ
        new_components = create_complete_ai_system()
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’æ›´æ–°
        openai_service = new_components.get('openai_service')
        intent_classifier = new_components.get('intent_classifier')
        category_search_engine = new_components.get('category_search_engine')
        
        # Slacké€šçŸ¥
        await slack_service.notify_ai_service_status(
            "AI_SYSTEM", 
            "RELOADED",
            {
                "openai": openai_service is not None,
                "intent_classifier": intent_classifier is not None,
                "category_search": category_search_engine is not None
            }
        )
        
        return {
            "status": "success",
            "message": "AIã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£å¸¸ã«å†èª­ã¿è¾¼ã¿ã•ã‚Œã¾ã—ãŸ",
            "components_reloaded": {
                "openai_service": openai_service is not None,
                "intent_classifier": intent_classifier is not None,
                "category_search_engine": category_search_engine is not None
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        LOGGER.error(f"âŒ AIã‚µãƒ¼ãƒ“ã‚¹å†èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return {
            "status": "error",
            "message": f"AIã‚µãƒ¼ãƒ“ã‚¹ã®å†èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡
project_root = Path(__file__).parent.parent
static_paths_to_try = [
    Path(__file__).parent / "static",
    project_root / "static",
    project_root / "src" / "static",
]

# app.pyã®æœ€å¾Œã«ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ 

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡ã®è¨­å®š
from fastapi.staticfiles import StaticFiles
from pathlib import Path

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š
static_dir = Path(__file__).parent / "static"

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ãƒã‚¦ãƒ³ãƒˆ
if static_dir.exists():
    app.mount("/src/static", StaticFiles(directory=str(static_dir)), name="static")
    LOGGER.info(f"âœ… é™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡ã‚’è¨­å®š: {static_dir}")
else:
    LOGGER.warning(f"âš ï¸ é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {static_dir}")

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚é…ä¿¡ï¼ˆindex.htmlã¨åŒã˜éšå±¤ï¼‰
project_root = Path(__file__).parent.parent
if (project_root / "static").exists():
    app.mount("/static", StaticFiles(directory=str(project_root / "static")), name="root_static")
    LOGGER.info(f"âœ… ãƒ«ãƒ¼ãƒˆé™çš„ãƒ•ã‚¡ã‚¤ãƒ«é…ä¿¡ã‚’è¨­å®š: {project_root / 'static'}")

# å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®é…ä¿¡ï¼ˆscript.js, style.cssï¼‰
src_static_dir = Path(__file__).parent / "static"
if src_static_dir.exists():
    app.mount("/script.js", StaticFiles(directory=str(src_static_dir)), name="script")
    app.mount("/style.css", StaticFiles(directory=str(src_static_dir)), name="style")

# ãƒ‡ãƒãƒƒã‚°ç”¨: é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç¢ºèª
@app.get("/debug/static-paths")
async def debug_static_paths():
    """é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±"""
    project_root = Path(__file__).parent.parent
    src_static = Path(__file__).parent / "static"
    
    return {
        "project_root": str(project_root),
        "src_static_dir": str(src_static),
        "src_static_exists": src_static.exists(),
        "script_js_exists": (src_static / "script.js").exists(),
        "style_css_exists": (src_static / "style.css").exists(),
        "project_structure": {
            "files_in_src": list(f.name for f in src_static.iterdir()) if src_static.exists() else [],
            "files_in_root": list(f.name for f in project_root.iterdir() if f.is_file())
        }
    }