# enhanced_sheet_service.py - ãƒ‘ã‚¹ä¿®æ­£ç‰ˆ

"""
æ‹¡å¼µã•ã‚ŒãŸGoogle Sheets/CSVã‚µãƒ¼ãƒ“ã‚¹
FAQæ©Ÿèƒ½ã¨ã‚«ãƒ†ã‚´ãƒªãƒ¼æ¤œç´¢ã«å¯¾å¿œ - Renderç’°å¢ƒå¯¾å¿œç‰ˆ
"""

import csv
import logging
import os
from typing import Dict, List, Optional
from datetime import datetime

LOGGER = logging.getLogger(__name__)

class SheetAccessException(Exception):
    """ã‚·ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ã‚¹é–¢é€£ã®ä¾‹å¤–"""
    pass

class EnhancedGoogleSheetsService:
    """æ‹¡å¼µã•ã‚ŒãŸCSV/ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚µãƒ¼ãƒ“ã‚¹ï¼ˆFAQå¯¾å¿œãƒ»Renderä¿®æ­£ç‰ˆï¼‰"""
    
    def __init__(self, csv_path: str):
        """
        Args:
            csv_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        # ğŸ”§ ãƒ‘ã‚¹è§£æ±ºãƒ­ã‚¸ãƒƒã‚¯ã‚’ä¿®æ­£
        self.csv_path = self._resolve_csv_path(csv_path)
        
        self._cache: Optional[List[Dict[str, str]]] = None
        self._cache_timestamp: Optional[datetime] = None
        self.cache_ttl_seconds = 300  # 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
        # CSVã®ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆæ—¥æœ¬èªï¼‰ã‹ã‚‰è‹±èªã‚­ãƒ¼ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.field_mapping = {
            'è³ªå•': 'question',
            'å›ç­”': 'answer',
            'å¯¾å¿œã‚«ãƒ†ã‚´ãƒªãƒ¼': 'category',
            'æ ¹æ‹ è³‡æ–™': 'source',
            'å‚™è€ƒ': 'notes',
            'FAQ_ID': 'faq_id',
            'è¡¨ç¤ºé †åº': 'display_order'
        }
        
        LOGGER.info(f"EnhancedGoogleSheetsService initialized with CSV: {self.csv_path}")

    def _resolve_csv_path(self, csv_path: str) -> str:
        """CSVãƒ‘ã‚¹ã‚’é©åˆ‡ã«è§£æ±ºã™ã‚‹"""
        
        # ğŸ”§ è¤‡æ•°ã®ãƒ‘ã‚¹å€™è£œã‚’è©¦è¡Œ
        possible_paths = [
            csv_path,                                    # å…ƒã®ãƒ‘ã‚¹
            os.path.join("src", "qa_data.csv"),         # src/qa_data.csv
            os.path.join(".", "src", "qa_data.csv"),    # ./src/qa_data.csv  
            "qa_data.csv",                              # qa_data.csv
            os.path.join("..", "qa_data.csv")           # ../qa_data.csv
        ]
        
        # å­˜åœ¨ã™ã‚‹ãƒ‘ã‚¹ã‚’æ¢ã™
        for path in possible_paths:
            abs_path = os.path.abspath(path)
            if os.path.exists(path):
                LOGGER.info(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {path} â†’ {abs_path}")
                return path
            else:
                LOGGER.debug(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ç„¡ã—: {path} â†’ {abs_path}")
        
        # ã©ã‚Œã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ƒã®ãƒ‘ã‚¹ã‚’è¿”ã™ï¼ˆã‚¨ãƒ©ãƒ¼ã¯å¾Œã§å‡¦ç†ï¼‰
        LOGGER.warning(f"âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ãŒã€å…ƒã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨: {csv_path}")
        return csv_path

    def _normalize_row(self, row: Dict[str, str]) -> Dict[str, str]:
        """CSVã®è¡Œãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ï¼ˆæ—¥æœ¬èªã‚­ãƒ¼ â†’ è‹±èªã‚­ãƒ¼ï¼‰"""
        normalized = {}
        
        for jp_key, en_key in self.field_mapping.items():
            value = row.get(jp_key, '').strip()
            
            # è¡¨ç¤ºé †åºã¯æ•°å€¤ã«å¤‰æ›
            if en_key == 'display_order' and value:
                try:
                    normalized[en_key] = int(value)
                except ValueError:
                    normalized[en_key] = 999  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆæœ€å¾Œã«è¡¨ç¤ºï¼‰
            else:
                normalized[en_key] = value
                
        return normalized

    def _is_cache_valid(self) -> bool:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯"""
        if self._cache is None or self._cache_timestamp is None:
            return False
            
        elapsed = (datetime.now() - self._cache_timestamp).total_seconds()
        return elapsed < self.cache_ttl_seconds

    async def get_qa_data(self, force_refresh: bool = False) -> List[Dict[str, str]]:
        """Q&Aãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰"""
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆã¯ãã‚Œã‚’è¿”ã™
        if not force_refresh and self._is_cache_valid():
            LOGGER.debug(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰Q&Aãƒ‡ãƒ¼ã‚¿ã‚’è¿”å´: {len(self._cache)}ä»¶")
            return self._cache
        
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            if not os.path.exists(self.csv_path):
                # ğŸ”§ å­˜åœ¨ã—ãªã„å ´åˆã¯å†åº¦ãƒ‘ã‚¹è§£æ±ºã‚’è©¦è¡Œ
                LOGGER.warning(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.csv_path}")
                self.csv_path = self._resolve_csv_path(self.csv_path)
                
                if not os.path.exists(self.csv_path):
                    raise SheetAccessException(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.csv_path}")
            
            with open(self.csv_path, newline='', encoding='utf-8') as fp:
                reader = csv.DictReader(fp)
                rows = []
                
                for row_num, row in enumerate(reader, start=2):  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è€ƒæ…®ã—ã¦2ã‹ã‚‰é–‹å§‹
                    # ç©ºè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if not any(value.strip() for value in row.values()):
                        continue
                        
                    try:
                        normalized_row = self._normalize_row(row)
                        rows.append(normalized_row)
                    except Exception as e:
                        LOGGER.warning(f"è¡Œ {row_num} ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
                        continue
                
                self._cache = rows
                self._cache_timestamp = datetime.now()
                
                LOGGER.info(f"{self.csv_path} ã‹ã‚‰ {len(self._cache)} ä»¶ã®Q&Aã‚¨ãƒ³ãƒˆãƒªã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                return self._cache
                
        except FileNotFoundError as exc:
            raise SheetAccessException(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.csv_path}") from exc
        except UnicodeDecodeError as exc:
            raise SheetAccessException(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {exc}") from exc
        except Exception as exc:
            raise SheetAccessException(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}") from exc

    async def get_faqs_by_category(self, category: str) -> List[Dict[str, str]]:
        """ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®FAQã‚’å–å¾—"""
        try:
            data = await self.get_qa_data()
            
            # FAQã®ã¿ã‚’æŠ½å‡ºï¼ˆå‚™è€ƒãŒã€Œã‚ˆãã‚ã‚‹è³ªå•ã€ã§FAQ_IDãŒå­˜åœ¨ã™ã‚‹ã‚‚ã®ï¼‰
            faqs = []
            for row in data:
                row_category = row.get('category', '').lower().strip()
                row_notes = row.get('notes', '').strip()
                row_faq_id = row.get('faq_id', '').strip()
                
                if (row_category == category.lower() and 
                    row_notes == 'ã‚ˆãã‚ã‚‹è³ªå•' and 
                    row_faq_id):
                    faqs.append(row)
            
            # è¡¨ç¤ºé †åºã§ã‚½ãƒ¼ãƒˆ
            faqs.sort(key=lambda x: x.get('display_order', 999))
            
            LOGGER.info(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼ '{category}' ã®FAQ {len(faqs)}ä»¶ã‚’å–å¾—")
            return faqs
            
        except Exception as e:
            LOGGER.error(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥FAQå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    async def get_faq_by_id(self, faq_id: str) -> Optional[Dict[str, str]]:
        """FAQ IDã§ç‰¹å®šã®FAQã‚’å–å¾—"""
        try:
            data = await self.get_qa_data()
            
            for row in data:
                if row.get('faq_id') == faq_id:
                    LOGGER.info(f"FAQ ID '{faq_id}' ã‚’å–å¾—")
                    return row
            
            LOGGER.warning(f"FAQ ID '{faq_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
            
        except Exception as e:
            LOGGER.error(f"FAQ IDæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    async def get_categories_summary(self) -> Dict[str, Dict[str, any]]:
        """ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        try:
            data = await self.get_qa_data()
            categories = {}
            
            for row in data:
                category = row.get('category', '').strip()
                if not category:
                    continue
                    
                if category not in categories:
                    categories[category] = {
                        'total_count': 0,
                        'faq_count': 0,
                        'general_count': 0
                    }
                
                categories[category]['total_count'] += 1
                
                if row.get('notes') == 'ã‚ˆãã‚ã‚‹è³ªå•':
                    categories[category]['faq_count'] += 1
                else:
                    categories[category]['general_count'] += 1
            
            LOGGER.info(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼çµ±è¨ˆ: {len(categories)}ã‚«ãƒ†ã‚´ãƒªãƒ¼")
            return categories
            
        except Exception as e:
            LOGGER.error(f"ã‚«ãƒ†ã‚´ãƒªãƒ¼çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def search_qa_data(
        self, 
        query: str, 
        category: Optional[str] = None,
        include_faqs_only: bool = False
    ) -> List[Dict[str, str]]:
        """Q&Aãƒ‡ãƒ¼ã‚¿ã®æ¤œç´¢ï¼ˆã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ãï¼‰"""
        try:
            data = await self.get_qa_data()
            results = []
            
            query_lower = query.lower().strip()
            
            for row in data:
                # ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                if category:
                    row_category = row.get('category', '').lower().strip()
                    if row_category != category.lower():
                        continue
                
                # FAQã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                if include_faqs_only and row.get('notes') != 'ã‚ˆãã‚ã‚‹è³ªå•':
                    continue
                
                # ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ï¼ˆè³ªå•ã¨å›ç­”ã®ä¸¡æ–¹ã§æ¤œç´¢ï¼‰
                question = row.get('question', '').lower()
                answer = row.get('answer', '').lower()
                
                if query_lower in question or query_lower in answer:
                    results.append(row)
            
            LOGGER.info(f"æ¤œç´¢ã‚¯ã‚¨ãƒª '{query}' (ã‚«ãƒ†ã‚´ãƒªãƒ¼: {category}): {len(results)}ä»¶")
            return results
            
        except Exception as e:
            LOGGER.error(f"Q&Aæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        self._cache = None
        self._cache_timestamp = None
        LOGGER.info("Q&Aãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

    def get_cache_info(self) -> Dict[str, any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æƒ…å ±ã‚’å–å¾—"""
        return {
            'cached': self._cache is not None,
            'cache_size': len(self._cache) if self._cache else 0,
            'cache_timestamp': self._cache_timestamp.isoformat() if self._cache_timestamp else None,
            'cache_valid': self._is_cache_valid(),
            'csv_path': self.csv_path,
            'csv_exists': os.path.exists(self.csv_path),
            'csv_absolute_path': os.path.abspath(self.csv_path)
        }